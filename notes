///////////////////////////////////////////////////////////////////////
BEST Practices

//////////////////////////////////////////////////////////////////////

PID 1 in Docker Containers
In Docker containers, the first process started (PID 1) has special responsibilities:

tini is a tiny but valid init system for Linux-based containers. It is designed to handle the responsibilities of PID 1 in a container, which include:

Reaping Zombie Processes: When a process terminates, its parent process must read its exit status. If the parent process does not do this, the terminated process becomes a "zombie" and can consume system resources. tini ensures that all child processes are properly reaped.

Forwarding Signals: Containers often need to handle system signals (e.g., SIGTERM, SIGINT) correctly to ensure graceful shutdowns. tini forwards these signals to the child processes, allowing them to handle the signals appropriately.

It reaps zombie processes.
It handles system signals.
If the process running as PID 1 in a container does not handle these responsibilities correctly, it can lead to issues such as memory leaks and improper signal handling.

Best Practices for Writing Dockerfiles
Use Official Base Images: Start with a minimal and secure base image.

Minimize Layers: Combine commands to reduce the number of layers.

Use Multi-Stage Builds: Reduce the final image size by using multi-stage builds.

Set a Non-Root User: Run your application as a non-root user for better security.

Use ENTRYPOINT and CMD Correctly: Use ENTRYPOINT for the main command and CMD for default arguments.

Handle PID 1 Correctly: Use an init system like tini to handle PID 1 responsibilities.

Example Dockerfile for WordPress


NGINX with TLSv1.2 or TLSv1.3 only =  config ssl(predecesseur de tsl) = > change les urls de http en https = securisation. 



///////////////////////////////////////////////////////////////////////
AVANT EVALUATION

//////////////////////////////////////////////////////////////////////

- changer sur le port 443 (sudo ). jai mis 1080 pour linstant 

V√©rifier que quand tu stop tes docker et que tu les relances tes donn√©es sont toujours pr√©sentes 

Pour se faire :
se log avec login.42.fr/wp-admin 
(Soit retourn√© sur la page d‚Äôaccueil et sur le poste, soit dans la page admin) √©crire un commentaire sur un poste ou en cr√©er un nouveau.
Si quand tu red√©marre le commentaire est encore l√† 
Il te reste plus que 2 chose √† v√©rifier :
Si tu a bien 2 user wordpresss (un admin et un autre (ATTENTION PAS DE LOGIN+MDP FACILE))

Et v√©rifier que tout tes mots de passe sont dans le .env que TU NE PUSH PAS et que tu ajoutera √† la main √† chaque correction
V√©rifie aussi si tu peux te connecter √† ton docker mariadb (command docker exec) 
normalement tu ne dois pas pouvoir te co en root sans mot passe (mysqld -h localhost -u root) si ca marche sans -p=$PASSWORD c‚Äôest pas bon
(Pour le modifier je te laisse checker comment Alter Table un User ROOT) 

///////////////////////////////////////////////////////////////////////

Tips VM :
passer en NAT plutot quen bridge
 run alias wp="wp --allow-root"

////////////////////////////////////////////////:
 GENERAL - docker:

////////////////////////////////////////////////

qller dqns le dosier de lappli
lancer docker build . ou par ex docker build -t nginx.

docker image ls


L'option -it que vous avez utilis√©e signifie :
-i : interactif
-t : alloue un pseudo-TTY

//////////////////////////////////////////////////
DOCKERFILE nginx
/////////////////////////////////////////////////////////

   openssl req


üí°
La commande req cr√©e et traite principalement des demandes de certificats au format PKCS#10. Elle peut en outre cr√©er des certificats auto-sign√©s.

RUN mkdir -p /etc/nginx/ssl -  dossier, qui permettra de stocker le certificat et la clef pour une connexion s√©curis√©e


OpenSSL:  l‚Äôoutil principal pour la gestion/cr√©ation de certificat SSL
Nous rajouterons ensuite le mot clef -x509 pour pr√©ciser le type du certificat.

-nodes : eviter la demande de mdp


-out /etc/nginx/ssl/inception.crt -keyout /etc/nginx/ssl/inception.key  :  indiquer √† OpenSSL o√π l‚Äôon souhaite stocker le certificat et la clef de notre SSL en rajoutant les options -out et -keyout

-subj eviter  d‚Äôavoir un prompt qui requiert certaines informations pour le certificat.

   RUN mkdir -p /var/run/nginx :  cr√©er un dossier qui nous permettra de stocker les fichiers de config de NGINX.


   Fonctionnement
Par d√©faut, Nginx s'ex√©cute comme un d√©mon, ce qui signifie qu'il fonctionne en arri√®re-plan.
L'option "-g 'daemon off;'" force Nginx √† rester au premier plan.
Utilit√© dans Docker
Cette configuration est particuli√®rement utile dans un environnement Docker pour plusieurs raisons :
Visibilit√© des logs : En mode premier plan, Nginx affiche ses logs directement dans la console du conteneur, facilitant le d√©bogage.
Gestion des processus : Docker peut mieux surveiller et g√©rer le processus Nginx lorsqu'il est au premier plan.
Arr√™t propre : Cela permet √† Docker d'envoyer correctement les signaux d'arr√™t √† Nginx lors de l'arr√™t du conteneur.

//////////////////////////////////////////////////
DOCKER COMPOSE
/////////////////////////////////////////////////////////

   docker-compose -f  <path_docker_compose>  -d ‚Äîbuild =>  build le docker compose 
   Pour l‚Äôarr√™ter :    docker-compose -f  <path_docker_compose>  stop
   Pour supprimer le build :    docker-compose -f  <path_docker_compose>  down -v

   Si vous rencontrez des probl√®mes avec docker vous pouvez utiliser la commande :

   docker system prune -af



//////////////////////////////////////////////////
EXPLICATION MAKEFILE
/////////////////////////////////////////////////////////

.PHONY: up
up: $(WORDPRESS_VOLUME_PATH) $(MARIADB_VOLUME_PATH)
	$(DOCKER_COMPOSE) up --build 
   ==> Cette r√®gle d√©marre les conteneurs en reconstruisant les images si n√©cessaire.


   docker-compose down
Cette commande :
Arr√™te tous les conteneurs en cours d'ex√©cution.
Supprime les conteneurs arr√™t√©s.
Supprime les r√©seaux d√©finis dans le fichier docker-compose.yml.
Par d√©faut, elle pr√©serve les volumes nomm√©s d√©finis dans le fichier docker-compose.yml1.
docker-compose stop
Cette commande :
Arr√™te les conteneurs en cours d'ex√©cution.
Conserve les conteneurs arr√™t√©s, les r√©seaux et les volumes1.



//////////////////////////////////////////////////
Fonctionnement
/////////////////////////////////////////////////////////


Les requ√™tes entrantes arrivent sur le port 443 de Nginx.
Nginx transmet les requ√™tes PHP √† WordPress sur le port 9000.
WordPress traite la requ√™te, en se connectant si n√©cessaire √† MariaDB sur le port 3306.
WordPress renvoie le r√©sultat √† Nginx.
Nginx renvoie la r√©ponse finale au client.


////////////////////////////////////////////////////////////////////////////////////////////////////
pourquoi utiliser un serveur proxy ? = un serveur situe devant un groupe dordinateurs clients  
///////////////////////////////////////////////////////////////////////////////////////////////////////////

Pour √©viter les restrictions de navigation impos√©es par l'√âtat ou les institutions : certains gouvernements, √©coles et autres organisations emploient des pare-feu pour offrir √† leurs utilisateurs un acc√®s √† une version limit√©e d'Internet. Un proxy de transfert peut permettre de contourner ces restrictions, car l'utilisateur se connecte alors au proxy plut√¥t que directement aux sites visit√©s.
Pour bloquer l'acc√®s √† certains contenus : inversement, la mise en place d'un proxy peut √©galement servir √† emp√™cher un groupe d'utilisateurs d'acc√©der √† certains sites. Un r√©seau scolaire peut, par exemple, √™tre configur√© pour se connecter au web par l'interm√©diaire d'un proxy disposant de r√®gles de filtrage de contenu charg√©es de refuser la transmission des r√©ponses provenant de Facebook et d'autres sites de r√©seaux sociaux.
Pour prot√©ger son identit√© en ligne : dans certains cas, les internautes ordinaires souhaitent simplement profiter d'un anonymat accru en ligne, mais dans d'autres, les internautes consid√©r√©s comme dissidents politiques par leur gouvernement peuvent s'exposer √† de graves sanctions dans certains pays. La critique du gouvernement sur un forum web ou sur les r√©seaux sociaux peut entra√Æner des amendes ou des peines d'emprisonnement pour ces utilisateurs. Si l'un de ces dissidents passe par un proxy de transfert pour se connecter √† un site web sur lequel il publie des commentaires politiquement sensibles, l'adresse IP utilis√©e pour publier ces commentaires sera plus difficile √† remonter. En effet, seule l'adresse IP du serveur proxy sera visible.

////////////////////////////////////////////////////////////////////////////////////////////////////
pourquoi utiliser un proxy inverse ? = un serveur situe devant un groupe de origin server  
///////////////////////////////////////////////////////////////////////////////////////////////////////////

√âquilibrage de charge : un site web populaire accueillant des millions d'utilisateurs chaque jour peut ne pas √™tre en mesure de g√©rer l'ensemble du trafic entrant sur son site √† l'aide d'un seul serveur d'origine. √Ä la place, le site peut √™tre r√©parti sur un ensemble de serveurs diff√©rents, tous d√©di√©s au traitement des requ√™tes pour le m√™me site. Dans ce cas, un proxy inverse peut constituer une solution d'√©quilibrage de charge permettant de distribuer le trafic entrant de mani√®re √©gale entre les diff√©rents serveurs afin d'√©viter la surcharge de l'un d'entre eux. En cas de d√©faillance compl√®te d'un serveur, les autres serveurs peuvent prendre le relais pour g√©rer le trafic.
Protection contre les attaques : avec un proxy inverse en place, un site ou un service web n'a jamais besoin de r√©v√©ler l'adresse IP de son ou ses serveurs d'origine. Il est donc beaucoup plus difficile pour les pirates de lancer une attaque cibl√©e contre eux, comme une attaque DDoS. Les pirates ne pourront alors viser que le proxy inverse (comme le r√©seau CDN de Cloudflare), qui peut compter sur une s√©curit√© plus stricte et davantage de ressources pour repousser une cyberattaque.
√âquilibrage de la charge des serveurs √† l'√©chelle mondiale (Global Server Load Balancing, GSLB) : cette forme d'√©quilibrage de charge permet √† un site web d'√™tre distribu√© sur plusieurs serveurs dans le monde entier. Le proxy inverse redirigera alors les clients vers le serveur le plus proche g√©ographiquement. Cette solution permet de r√©duire les distances que les requ√™tes et les r√©ponses doivent parcourir, minimisant ainsi les temps de chargement.
Mise en cache : un proxy inverse peut √©galement mettre en cache le contenu afin d'am√©liorer la rapidit√© d'un site. Ainsi, un utilisateur √† Paris visitant un site web associ√© √† un proxy inverse (et disposant de serveurs web √† Los Angeles) pourrait en fait se connecter √† un serveur proxy inverse local √† Paris, qui se chargera ensuite de communiquer avec un serveur d'origine √† Los Angeles. Le serveur proxy pourra alors mettre en cache (ou enregistrer temporairement) les donn√©es de r√©ponse. Les utilisateurs parisiens qui se rendront par la suite sur ce site obtiendront la version mise en cache localement en r√©ponse du serveur de proxy inverse parisien, entra√Ænant ainsi une exp√©rience de navigation plus rapide.
Chiffrement SSL : le chiffrement et le d√©chiffrement des communications SSL (ou TLS) de chaque client peuvent s'av√©rer co√ªteux en termes de calcul pour un serveur d'origine. Un proxy inverse peut ainsi √™tre configur√© pour d√©chiffrer toutes les requ√™tes entrantes et chiffrer l'ensemble des r√©ponses sortantes, afin de lib√©rer de pr√©cieuses ressources sur le serveur d'origine.

